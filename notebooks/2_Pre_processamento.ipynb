{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Base de dados com dados limpos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Suja\n",
    "carros = pd.read_csv('https://raw.githubusercontent.com/RafaelSilvax06/ProjetoIA-Analise/refs/heads/main/car_sales_data.csv')\n",
    "\n",
    "#Aplicando a mesma limpeza da fase 1\n",
    "\n",
    "# Tradução de colunas\n",
    "carros.columns = carros.columns = ['Fabricante', 'Modelo', 'Potencia Motor', 'Tipo Combustivel', 'Ano De Fabricacao', 'Quilometragem', 'Preco']\n",
    "\n",
    "# Convertando preço em reais.\n",
    "carros['Preco'] = carros['Preco'].astype(float)\n",
    "carros['Preco'] = carros['Preco'] * 5.38\n",
    "\n",
    "# Converter Quilometragem para float.\n",
    "carros['Quilometragem'] = carros['Quilometragem'].astype(float)\n",
    "\n",
    "# Removendo valores irreais (Preços abaixo de R$ 3.500,00)\n",
    "carros_valor_irreais = carros[carros['Preco'] <= 3500.00].sort_values(by='Preco')\n",
    "carros.drop(index=carros_valor_irreais.index, inplace=True)\n",
    "\n",
    "\n",
    "print('Dados limpos e prontos para o pre processamento: ')\n",
    "print('\\n')\n",
    "carros.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Definição de X e Y\n",
    "Separando o conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo X e y para criar o modelo e trabalhar na regressão.\n",
    "\n",
    "# Y é o preço, nosso alvo.\n",
    "y = carros['Preco']\n",
    "# X é nossas pistas, colunas correlacionadas ao preço.\n",
    "X = carros.drop('Preco', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Divisão de treino com sklearn e train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usamos 80% para treino e 20% para teste.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Tamanho de X_train (treino): {X_train.shape[0]} amostras\") # 80% das amostras da base de dados.\n",
    "print(f\"Tamanho de X_test (teste): {X_test.shape[0]} amostras\") # 20% das amostras da base de dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Processamento de colunas.\n",
    "\n",
    "Nosso x_train ainda tem texto e numeros misturados, vamos separo-los para fazer uma boa regressão na modelagem.\n",
    "\n",
    "Vamos usar encoding e scaling.\n",
    "\n",
    "Encoding:Converter colunas de texto em colunas numericas, exemplo: Toyota vira 0, BMW vira 1, etc.\n",
    "\n",
    "Scaling: Padroniza as colunas numericas para ter medias e escalas semelhantes, assim deixando otimo o desempenho do modelo.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir quais colunas são de qual tipo\n",
    "colunas_categoricas = ['Fabricante', 'Modelo', 'Tipo Combustivel']\n",
    "colunas_numericas = ['Potencia Motor', 'Ano De Fabricacao', 'Quilometragem']\n",
    "\n",
    "# 2. Criar a \"esteira de processamento\" (ColumnTransformer)\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'), colunas_categoricas),\n",
    "        ('scaler', StandardScaler(), colunas_numericas)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# 3. Aplicar o processamento (TREINAR E TRANSFORMAR)\n",
    "X_train_processado = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# 4. Aplicar o processamento (APENAS TRANSFORMAR)\n",
    "X_test_processado = preprocessor.transform(X_test)\n",
    "\n",
    "# Verificar o resultado\n",
    "print(\"Dados processados com sucesso!\")\n",
    "print(f\"Shape de X_train_processado: {X_train_processado.shape}\")\n",
    "print(f\"Shape de X_test_processado: {X_test_processado.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma pasta para salvar os dados processados (se ela não existir)\n",
    "os.makedirs('../data_base/processed', exist_ok=True)\n",
    "\n",
    "# Salvar as 4 variáveis em arquivos .pkl (pickle)\n",
    "joblib.dump(X_train_processado, '../data_base/processed/X_train_processed.pkl')\n",
    "joblib.dump(X_test_processado, '../data_base/processed/X_test_processed.pkl')\n",
    "joblib.dump(y_train, '../data_base/processed/y_train.pkl')\n",
    "joblib.dump(y_test, '../data_base/processed/y_test.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
